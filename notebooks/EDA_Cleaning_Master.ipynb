{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c323b633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import SimpleImputer,IterativeImputer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db682324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read in csv file\n",
    "train = pd.read_csv('../Datasets/train.csv')\n",
    "test = pd.read_csv('../Datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aac93391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dropping columns with a lot of missing values and won't be used in analysis\n",
    "train = train.drop(columns = ['id', 'homepage', 'imdb_id', 'tagline', 'overview', 'crew', 'status','original_language', 'poster_path', 'title'])\n",
    "test = test.drop(columns = ['id', 'homepage', 'imdb_id', 'tagline', 'overview','crew','status','original_language', 'poster_path','title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e611228b-be9b-4aa6-9b96-c41a20552889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping columns where insights can be gained, but we are on a time crunch\n",
    "test = test.drop(columns = ['cast','Keywords','production_companies', 'spoken_languages'])\n",
    "train = train.drop(columns = ['cast','Keywords','production_companies','spoken_languages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81cc0f0c-5fae-4b18-a460-1580327c07d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   belongs_to_collection  604 non-null    object \n",
      " 1   budget                 3000 non-null   int64  \n",
      " 2   genres                 2993 non-null   object \n",
      " 3   original_title         3000 non-null   object \n",
      " 4   popularity             3000 non-null   float64\n",
      " 5   production_countries   2945 non-null   object \n",
      " 6   release_date           3000 non-null   object \n",
      " 7   runtime                2998 non-null   float64\n",
      " 8   revenue                3000 non-null   int64  \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 211.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eda231-5911-438a-8dac-0963b34404ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dealing with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6905be-f653-4880-b1d0-471b5c6a1d97",
   "metadata": {},
   "source": [
    "### belongs_to_collection -- binarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b0a6460-d1e1-47ca-a950-199bbd9d39dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['belongs_to_collection'] = train['belongs_to_collection'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18e20d13-0124-424d-ae3d-93daab6122d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['belongs_to_collection'] = test['belongs_to_collection'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de3283-4169-4338-a9e0-939fdfbeef9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### genres, production_countries, spoken_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a141f2c1-5b1c-47d0-a204-9d839f724436",
   "metadata": {},
   "source": [
    "# Note for ARjun. You need to deal with missing values before you can run the following functions as is. my suggestion is that u change the functionality of the functions such that they work despite the missing values and also think of the outputs because those are what you will be dummying.\n",
    "\n",
    "[heres lab 2.07 where you use ohe and make_column_transformer()](https://git.generalassemb.ly/kalymaan/lab-2.07-clustering/blob/main/starter-code.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99625daf-e237-4796-94d8-f5c0abe9e428",
   "metadata": {},
   "source": [
    "#### converting list of dictionaries which are written as strings into actual lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12c2b76d-adbe-415e-9260-cce50a372bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "big_dict = {'genres': 'name', \n",
    " #'production_companies': 'name', \n",
    " 'production_countries': 'name',\n",
    " 'spoken_languages': 'iso_639_1' # 'name' may be used... compare iso to original language, if same we drop\n",
    " # 'Keywords': 'name' \n",
    " #'cast': ['gender','order'], # take the 'gender' from 'order' = 0 ******************\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b0449-28b0-4915-be7e-e4e05533ba0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### This is a function for the loop below it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "666e70ca-580a-42c1-bab1-f217c6071346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_extractor(l, key_we_want):\n",
    "    # Input: l is the list we want to extract from.\n",
    "    #        key_we_want is the key we want lol\n",
    "    \n",
    "    return [d[key_we_want] for d in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553db73-eb1e-4248-8e6a-edbdb11c6025",
   "metadata": {},
   "source": [
    "#### This is where we tutrn those crazy columns into things we can work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5332144-e736-4e90-9394-4a7eedca4799",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: nan",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col_name, info_we_want \u001b[38;5;129;01min\u001b[39;00m big_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 4\u001b[0m     train[col_name] \u001b[38;5;241m=\u001b[39m train[col_name]\u001b[38;5;241m.\u001b[39mapply(ast\u001b[38;5;241m.\u001b[39mliteral_eval)\n\u001b[0;32m      5\u001b[0m     test[col_name] \u001b[38;5;241m=\u001b[39m test[col_name]\u001b[38;5;241m.\u001b[39mapply(ast\u001b[38;5;241m.\u001b[39mliteral_eval)\n\u001b[0;32m      7\u001b[0m     train[col_name] \u001b[38;5;241m=\u001b[39m train[col_name]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: feature_extractor(x, info_we_want))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ast.py:110\u001b[0m, in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert(node_or_string)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ast.py:109\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ast.py:83\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert_num(node)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ast.py:74\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[1;32m---> 74\u001b[0m         _raise_malformed_node(node)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ast.py:71\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lno \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     70\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: malformed node or string: nan"
     ]
    }
   ],
   "source": [
    "for col_name, info_we_want in big_dict.items():\n",
    "    \n",
    "    \n",
    "    train[col_name] = train[col_name].apply(ast.literal_eval)\n",
    "    test[col_name] = test[col_name].apply(ast.literal_eval)\n",
    "    \n",
    "    train[col_name] = train[col_name].apply(lambda x: feature_extractor(x, info_we_want))\n",
    "    test[col_name] = test[col_name].apply(lambda x: feature_extractor(x, info_we_want))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b557c-f9f0-49b3-bb75-f71658a7bef3",
   "metadata": {},
   "source": [
    "### ok turn releasedate into unix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a23d120-9d62-4357-8de1-50fa809746f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['release_date'] = train['release_date'].apply(lambda x: int(datetime.strptime(x, \"%m/%d/%y\").timestamp()))\n",
    "test['release_date'] = test['release_date'].apply(lambda x: int(datetime.strptime(x, \"%m/%d/%y\").timestamp()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673b9e71-254f-4a44-b7b3-c8e5df78c448",
   "metadata": {},
   "source": [
    "## dummifying the categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771ea09-bf5b-48f5-9546-30869c9c60a3",
   "metadata": {},
   "source": [
    "Will not be dropping first in the following three categorical values because they are all multicategory(not mutually exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1993a25e-e23b-4b0c-b4e2-ebbc695784fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df = pd.concat([train,test],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6da4969-fc40-4627-a7d1-ab4b35e2fea5",
   "metadata": {},
   "source": [
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1daf6d0-4415-4ebb-8342-1d971008d7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genres_dummies = pd.get_dummies(combined_df['genres'].explode(), prefix='genre')\n",
    "\n",
    "genres_dummies = genres_dummies.groupby(genres_dummies.index).sum()\n",
    "\n",
    "combined_df = pd.concat([combined_df,genres_dummies], axis=1)\n",
    "\n",
    "combined_df.drop('genres', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe246229-a92d-4517-ad2b-0c7419faa120",
   "metadata": {
    "tags": []
   },
   "source": [
    "production_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd3764df-e0a2-4524-9777-1516857c313f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "production_country_dummies = pd.get_dummies(combined_df['production_countries'].explode(), prefix='prod_country')\n",
    "\n",
    "production_country_dummies = production_country_dummies.groupby(production_country_dummies.index).sum()\n",
    "\n",
    "combined_df = pd.concat([combined_df,production_country_dummies], axis=1)\n",
    "\n",
    "combined_df.drop('production_countries', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b2a363-863d-4ce1-994c-2823ca665258",
   "metadata": {},
   "source": [
    "spoken language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4b7831e-bb50-4bb3-bf73-8b4afe41f474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spoken_language_dummies = pd.get_dummies(combined_df['spoken_languages'].explode(), prefix='spoken_lang')\n",
    "\n",
    "spoken_language_dummies = spoken_language_dummies.groupby(spoken_language_dummies.index).sum()\n",
    "\n",
    "combined_df = pd.concat([combined_df,spoken_language_dummies], axis=1)\n",
    "\n",
    "combined_df.drop('spoken_languages', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "304273b9-29f2-4068-b362-7eef4dfbf6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6457, 216)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2247fb77-be27-4e53-ace1-a4273f1a0fc2",
   "metadata": {},
   "source": [
    "# Making a length of title column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75e6ceb2-994c-4379-b93f-aae87712c21a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_df['length_of_title'] = combined_df['original_title'].str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80c7b0c8-32d5-4684-9906-d2cc15aec266",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(columns=['original_title'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38644dc7-e2a9-48bd-8ac3-e5d66409af9c",
   "metadata": {},
   "source": [
    "Ok splitting the daatafram back into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6c31251-b8b4-488a-958f-5beac48a6eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['release_date']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cols = list(combined_df.select_dtypes('object').columns.values)\n",
    "object_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f798c6b3-6c36-4646-a2db-aa7c38688394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_cols = list(combined_df._get_numeric_data().columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27f01494-2906-4d14-aca3-2bcc7d8daae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "058d8a37-f719-45aa-b34d-4eff36df4daf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = len(train)\n",
    "train_dummified = combined_df[:train_size]\n",
    "test_dummified = combined_df[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31012a54-5a91-41d6-a57d-b7f6a9b527f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dummified = test_dummified.drop(columns=['revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d867a0a6-c98b-4482-9629-28ffa6f86c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3834, 215)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dummified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bc92020-f8db-48c4-89bb-2a5579c2ce09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2623, 216)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dummified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713f691-264c-4b30-8c59-9415c575970d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
